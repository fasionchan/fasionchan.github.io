<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | fasionchan]]></title>
  <link href="http://blog.fasionchan.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://blog.fasionchan.com/"/>
  <updated>2017-06-16T15:10:30+08:00</updated>
  <id>http://blog.fasionchan.com/</id>
  <author>
    <name><![CDATA[陈彦霏]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Procfs伪文件系统原理]]></title>
    <link href="http://blog.fasionchan.com/blog/2017/06/16/procfswei-wen-jian-xi-tong-yuan-li/"/>
    <updated>2017-06-16T14:58:23+08:00</updated>
    <id>http://blog.fasionchan.com/blog/2017/06/16/procfswei-wen-jian-xi-tong-yuan-li</id>
    <content type="html"><![CDATA[<p><code>Linux</code>系统<code>/proc</code>目录下，有一些特殊的目录和文件，用来展示或者设置内核数据。例如，<code>/proc/meminfo</code>展示系统内存信息：</p>

<pre><code>$ cat /proc/meminfo
MemTotal:         506160 kB
MemFree:           73528 kB
MemAvailable:     335160 kB
Buffers:           54756 kB
Cached:           162888 kB
SwapCached:            0 kB
Active:           247648 kB
Inactive:          96840 kB
Active(anon):     127044 kB
Inactive(anon):     4332 kB
Active(file):     120604 kB
Inactive(file):    92508 kB
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:               104 kB
Writeback:             0 kB
AnonPages:        126824 kB
Mapped:            14412 kB
Shmem:              4532 kB
Slab:              70608 kB
SReclaimable:      59128 kB
SUnreclaim:        11480 kB
KernelStack:        2928 kB
PageTables:         3028 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:      253080 kB
Committed_AS:     530132 kB
VmallocTotal:   34359738367 kB
VmallocUsed:        5536 kB
VmallocChunk:   34359731707 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:       69568 kB
DirectMap2M:      454656 kB
</code></pre>

<p>这些数据随着系统的变化动态调整，感觉好神奇！</p>

<!--more-->


<p>还有一些文件，直接跟一些内核变量映射。除了可以读出数据，还可以更新数据呢。例如，<code>/proc/sys/net/ipv4/ip_forward</code>用来控制<code>IP</code>包转发，设置为<code>1</code>则是是启用转发：</p>

<pre><code>$ cat /proc/sys/net/ipv4/ip_forward
0
echo "1" &gt; /proc/sys/net/ipv4/ip_forward
$ cat /proc/sys/net/ipv4/ip_forward
1
</code></pre>

<p>那么，这些文件本质是什么呢？是真正的文件吗？</p>

<h2>来龙去脉</h2>

<p>系统用户和程序(进程)经常需要某些内核信息，该怎么获得呢？</p>

<p>以<code>/proc/sys/net/ipv4/ip_forward</code>为例，内核里有一个变量用来控制协议栈是否转发<code>IP</code>包。系统用户要控制转发是否开启，就需要去设置这个内核变量。怎么设置呢？要知道用户空间可是没有办法直接访问内核空间的。</p>

<p>可以考虑实现一个新的系统调用——<code>int set_ip_forward(int value)</code>。然而，天呀有好多这样或那样的场景，这样系统调用表是要爆炸的！而且这种方式用起来也麻烦，需要实现一个专用的命令，调用这个系统调用完成设置。</p>

<p>有没有更通用的方式呢？其实，让这个系统调用更加通用化，也是一种思路——<code>int set_kernel_value(char *path, void *value)</code>。这样一个系统调用就搞定了一些列设置要求，但是还是没有解决调用麻烦的问题。</p>

<p>如果，可以将内核数据伪装成一个文件，用<code>read</code>系统调用获取；用<code>write</code>系统调用设置不就完美了吗？这样，有现成的命令可以直接使用，比如用<code>cat</code>来获取，用<code>echo</code>来设置！</p>

<p>那么内核有办法做到吗？</p>

<p>办法肯定是有的。最直观的想法是，在内核处理<code>read</code>的代码进行控制，让<code>read</code>直接从内核数据中拷贝，而不是磁盘。当然了，内核黑客们不会写这么恶心的代码，而是抽象了一层——<code>VFS</code>。</p>

<h2>VFS</h2>

<p><code>Linux</code>支持各种各样的文件系统，光<code>ext</code>系列就有：<code>ext2</code>、<code>ext3</code>、<code>ext4</code>。内核如何实现不同文件系统差异性的呢？</p>

<p>答案是，内核抽象了<code>VFS</code>接口。跟面向对象编程中的接口有点类似，具体的文件系统按照各自的方式分别实现(多态)。</p>

<p><img src="http://upload-images.jianshu.io/upload_images/2740477-e2afa3b8415de815.gif?imageMogr2/auto-orient/strip" alt="archi_VFS-eng.gif" /></p>

<p>如上图所示，不同的文件系统以各自的方式实现处理接口，如<code>read</code>和<code>write</code>等等。这些处理接口被封装成结构一致的结构体注册。这样，同样的系统调用，在不同的文件系统下，由不同的函数处理。</p>

<p>因此，完全有可能实现一个假的文件系统，就叫<code>procfs</code>，读写分别映射为变量的读出和写入。</p>

<h2>流程</h2>

<p>最后，图解说明访问<code>/proc</code>下文件的整个流程：</p>

<p><img src="http://upload-images.jianshu.io/upload_images/2740477-d7d7a62d6c2c427d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="procfs" /></p>

<ol>
<li>用户进程发起一个系统调用<code>read</code>；</li>
<li>内核<code>VFS</code>根据文件描述符找出操作描述体；</li>
<li>内核从描述体取出<code>read</code>处理函数指针；</li>
<li>内核执行该处理函数；</li>
<li>处理函数读出内核变量并拷贝到用户态空间；</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux内核模块]]></title>
    <link href="http://blog.fasionchan.com/blog/2017/06/14/linux-nei-he-mo-kuai/"/>
    <updated>2017-06-14T11:37:33+08:00</updated>
    <id>http://blog.fasionchan.com/blog/2017/06/14/linux-nei-he-mo-kuai</id>
    <content type="html"><![CDATA[<p>Linux内核管理着一台计算机的所有资源，为上层应用程序提供统一的编程接口(系统调用)，屏蔽底层设备的差异。
由于不同用户物理设备以及对内核功能需求的差异性，需要一种类似插件的运行机制——编写插件实现所需功能，然后嵌入到内核中，与内核形成一个整体。</p>

<p><strong>Linux内核模块</strong>便是这样的插件。作为Linux内核的扩展手段，可以在运行时动态加载和卸载。
那么，一个内核模块是怎么编写的呢？与普通程序编写有什么区别呢？</p>

<p>程序开发经常以<code>hello world</code>程序入门，因为这是最简单的。
本文也通过一个最简单的内核模块，演示如何一步步编写一个内核模块。</p>

<!--more-->


<h1>结构</h1>

<p>内核模块与普通程序不同，没有执行流。
可以这样理解，内核模块实现一些函数，作为回调函数注册到内核中。
在内核加载/卸载时，或者其他应用程序调用系统调用时，注册的回调函数才得到调用。</p>

<p>有两个最基本的回调函数<code>init</code>和<code>exit</code>，分别由<code>module_init</code>和<code>module_exit</code>登记，分别在模块加载和卸载的时候执行。
下面实现的<code>hello world</code>内核模块，将只实现这两个最基本的函数。</p>

<p>内核模块支持参数，用户借此控制内核模块的行为。
参数有默认值，可以在加载时指定，也可以在通过<code>proc</code>伪文件系统等手段动态修改。</p>

<p>此外，内核模块还需要带一些描述信息，包括许可证、作者、描述以及版本等等。
描述信息由<code>MODULE_</code>系列宏指定，<code>modinfo</code>等命令可以展示这些信息。</p>

<h1>编码</h1>

<p>开干了！新建一个文件，<code>hello.c</code>用于实现一个玩具型内核模块——<code>hello</code>模块。</p>

<p><code>hello</code>模块只实现<code>init</code>和<code>exit</code>函数，分别在加载和卸载时往内核日志输出一条记录。
同时，也演示了参数的使用方式——通过参数控制日志输出内容。</p>

<pre><code class="c">/**
 * FileName:   hello.c
 * Author:     Chen Yanfei
 * @contact:   fasionchan@gmail.com
 * @version:   $Id$
 *
 * Description:
 *
 * Changelog:
 *
 **/

// 引入相关内核头文件
#include &lt;linux/module.h&gt;

// 内核模块信息，包括许可证、作者、描述和版本等
MODULE_LICENSE("GPL");
MODULE_AUTHOR("Fasion Chan");
MODULE_DESCRIPTION("An hello worlk module for demonstration");
MODULE_VERSION("1.0");

// 内核模块参数，加载时指定或者动态指定，以此控制模块行为
static char *name = "world";
module_param(name, charp, S_IRUGO);
MODULE_PARM_DESC(name, "Whom this module say hello to");


// 初始化函数，在加载时调用，分配资源准备执行环境
// 这里只是往内核日志输出一行记录
static int __init hello_init(void)
{
    printk(KERN_INFO "HELLO: Hello %s, this is hello module speaking\n", name);
    return 0;
}


// 清理函数，在卸载时调用，回收资源销毁执行环境
static void __exit hello_exit(void)
{
    printk(KERN_INFO "HELLO: Goodbye %s", name);
}

// 登记初始化函数及清理函数
module_init(hello_init);
module_exit(hello_exit);
</code></pre>

<h1>编译</h1>

<p>内核模块代码已经写好了，怎样知道写得对不对呢？编译运行一下不就知道了？
可问题是如何编译呢？跟普通程序一样吗？用<code>gcc</code>来编译？</p>

<p>没错，内核模块用<code>gcc</code>来编译，但不会直接运行<code>gcc</code>。
我们需要先准备一个<code>Makefile</code>，内容如下：</p>

<pre><code>obj-m+=hello.o

all:
    make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) modules

clean:
    make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) modules
</code></pre>

<p>好了之后，我们再命令行下运行<code>make</code>即可：</p>

<pre><code>$ ls
hello.c  Makefile
$ make
make -C /lib/modules/3.16.0-4-amd64/build/ M=/home/fasion/hello modules
make[1]: Entering directory '/usr/src/linux-headers-3.16.0-4-amd64'
make[1]: Entering directory `/usr/src/linux-headers-3.16.0-4-amd64'
  CC [M]  /home/fasion/hello/hello.o
  Building modules, stage 2.
  MODPOST 1 modules
  CC      /home/fasion/hello/hello.mod.o
  LD [M]  /home/fasion/hello/hello.ko
make[1]: Leaving directory '/usr/src/linux-headers-3.16.0-4-amd64'
$ ls
hello.c  hello.ko  hello.mod.c  hello.mod.o  hello.o  Makefile  modules.order  Module.symvers
</code></pre>

<p>看到<code>hello.ko</code>文件生成，意味着编译大功告成了！
该文件就是二进制内核模块目标文件，其他文件的作用不再讨论了。</p>

<p>顺便提一句，<code>Makefile</code>中分成<code>all</code>和<code>clean</code>两节。
其中<code>all</code>用来编译，<code>clean</code>用来清理编译环境：</p>

<pre><code>$ make clean
make -C /lib/modules/3.16.0-4-amd64/build/ M=/home/fasion/hello clean
make[1]: Entering directory '/usr/src/linux-headers-3.16.0-4-amd64'
make[1]: Entering directory `/usr/src/linux-headers-3.16.0-4-amd64'
  CLEAN   /home/fasion/hello/.tmp_versions
  CLEAN   /home/fasion/hello/Module.symvers
make[1]: Leaving directory '/usr/src/linux-headers-3.16.0-4-amd64'
$ ls
hello.c  Makefile
</code></pre>

<p>可以看到，运行了<code>make clean</code>后，所有编译生成的文件都清理掉了，只剩源码文件和<code>Makefile</code>。</p>

<h1>运行</h1>

<p>内核模块编译完成后，要怎么使用呢？跟普通程序直接运行不同，内核模块需要加载到内核里面发挥作用。使用<code>insmod</code>命令加载内核模块：</p>

<pre><code>$ ls
hello.c  hello.ko  hello.mod.c  hello.mod.o  hello.o  Makefile  modules.order  Module.symvers
$ sudo insmod hello.ko
$ dmesg
[   14.226777] 00:00:00.000718 main     OS Product: Linux
[   14.226814] 00:00:00.000779 main     OS Release: 3.16.0-4-amd64
[   14.226845] 00:00:00.000814 main     OS Version: #1 SMP Debian 3.16.7-ckt20-1+deb8u4 (2016-02-29)
[   14.226873] 00:00:00.000844 main     OS Service Pack: #1 SMP Debian 3.16.7-ckt20-1+deb8u4 (2016-02-29)
[   14.226912] 00:00:00.000872 main     Executable: /opt/VBoxGuestAdditions-5.0.8/sbin/VBoxService
00:00:00.000873 main     Process ID: 716
00:00:00.000874 main     Package type: LINUX_64BITS_GENERIC
[   14.232015] 00:00:00.005962 main     5.0.8 r103449 started. Verbose level = 0
[ 4368.359895] HELLO: Hello world, this is hello module speaking
</code></pre>

<p>内核模块加载后，用<code>dmesg</code>命令看到，内核模块初始化时输出的一条内核日志。</p>

<p>加载内核模块时怎么指定参数的值呢？下面演示移除内核模块，并以<code>fasion</code>为<code>name</code>参数值重新挂载：</p>

<pre><code>$ sudo rmmod hello
$ sudo insmod hello.ko name=fasion
</code></pre>

<p>操作完成后，用<code>dmesg</code>可以看到以下内核日志：</p>

<pre><code>[ 4368.359895] HELLO: Hello world, this is hello module speaking
[ 4812.067761] HELLO: Goodbye world
[ 4841.011892] HELLO: Hello fasion, this is hello module speaking
</code></pre>

<p>第二次挂载时，<code>name</code>参数的值不是默认值<code>world</code>，而是<code>fasion</code>了。</p>

<p>跟内核模块相关还有<code>insmod</code>、<code>rmmod</code>、<code>lsmod</code>、<code>modinfo</code>、<code>modprobe</code>等命令，用法请参考<code>man</code>文档。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[译文]深入理解Linux TCP Backlog]]></title>
    <link href="http://blog.fasionchan.com/blog/2016/11/07/yi-wen-shen-ru-li-jie-linux-tcp-backlog/"/>
    <updated>2016-11-07T21:57:09+08:00</updated>
    <id>http://blog.fasionchan.com/blog/2016/11/07/yi-wen-shen-ru-li-jie-linux-tcp-backlog</id>
    <content type="html"><![CDATA[<p>当应用程序调用<code>listen</code>系统调用让一个<code>socket</code>进入<code>LISTEN</code>状态时，需要指定一个参数<code>backlog</code>。这个<code>backlog</code>参数经常被描述为，新连接队列的长度限制。</p>

<p><img src="http://upload-images.jianshu.io/upload_images/2740477-d1ebcbbc58e3b9f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="tcp-state-diagram.png" /></p>

<!--more-->


<p>由于<code>TCP</code>建立连接使用3次握手，因此，一个新连接在到达<code>ESTABLISHED</code>状态可以被<code>accept</code>系统调用返回给应用程序前，必须经过一个中间状态<code>SYN RECEIVED</code>(见上图)。这意味着，<code>TCP/IP</code>协议栈在实现<code>backlog</code>队列时，有两种不同的选择：</p>

<ol>
<li><p>仅使用一个队列，队列规模由<code>listen</code>系统调用<code>backlog</code>参数指定。当协议栈收到一个<code>SYN</code>包时，响应<code>SYN/ACK</code>包并且将连接加进该队列。当相应的<code>ACK</code>响应包收到后，连接变为<code>ESTABLISHED</code>状态，可以向应用程序返回。这意味着队列里的连接可以有两种不同的状态：<code>SEND RECEIVED</code>和<code>ESTABLISHED</code>。只有后一种连接才能被<code>accept</code>系统调用返回给应用程序。</p></li>
<li><p>使用两个队列——<code>SYN</code>队列(待完成连接队列)和<code>accept</code>队列(已完成连接队列)。状态为<code>SYN RECEIVED</code>的连接进入<code>SYN</code>队列，后续当状态变更为<code>ESTABLISHED</code>时移到<code>accept</code>队列(即收到3次握手中最后一个<code>ACK</code>包)。顾名思义，<code>accept</code>系统调用就只是简单地从<code>accept</code>队列消费新连接。在这种情况下，<code>listen</code>系统调用<code>backlog</code>参数决定<code>accept</code>队列的最大规模。</p></li>
</ol>


<p>历史上，起源于<code>BSD</code>的<code>TCP</code>实现使用第一种方法。这个方案意味着，但<code>backlog</code>限制达到，系统将停止对<code>SYN</code>包响应<code>SYN/ACK</code>包。通常，协议栈只是丢弃<code>SYN</code>包(而不是回一个<code>RST</code>包)以便客户端可以重试(而不是异常退出)。</p>

<p><code>TCP/IP详解 卷3</code>第<code>14.5</code>节中有提到这一点。书中作者提到，<code>BSD</code>实现虽然使用了两个独立的队列，但是行为跟使用一个队列并没什么区别。</p>

<p>在<code>Linux</code>上，情况有所不同，情况<code>listen</code>系统调用<code>man</code>文档页：</p>

<blockquote><p>The  behavior  of  the  backlog  argument on TCP sockets changed with Linux 2.2.  Now it specifies the queue length for completely established sockets waiting to be accepted, instead of the number of incomplete connection requests.  The maximum length of the queue for incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog.  When syncookies are enabled there is no logical maximum length and this setting is ignored.</p>

<p>意思是，<code>backlog</code>参数的行为在<code>Linux</code>2.2之后有所改变。现在，它指定了等待<code>accept</code>系统调用的已建立连接队列的长度，而不是待完成连接请求数。待完成连接队列长度由<code>/proc/sys/net/ipv4/tcp_max_syn_backlog</code>指定；在<code>syncookies</code>启用的情况下，逻辑上没有最大值限制，这个设置便被忽略。</p></blockquote>

<p>也就是说，当前版本的<code>Linux</code>实现了第二种方案，使用两个队列——一个<code>SYN</code>队列，长度系统级别可设置以及一个<code>accept</code>队列长度由应用程序指定。</p>

<p>现在，一个需要考虑的问题是在<code>accept</code>队列已满而一个已完成新连接需要用<code>SYN</code>队列移动到<code>accept</code>队列(收到3次握手中最后一个<code>ACK</code>包)，这个实现方案是什么行为。这种情况下，由<code>net/ipv4/tcp_minisocks.c</code>中<code>tcp_check_req</code>函数处理：</p>

<pre><code>    child = inet_csk(sk)-&gt;icsk_af_ops-&gt;syn_recv_sock(sk, skb, req, NULL);
    if (child == NULL)
        goto listen_overflow;
</code></pre>

<p>对于<code>IPv4</code>，第一行代码实际上调用的是<code>net/ipv4/tcp_ipv4.c</code>中的<code>tcp_v4_syn_recv_sock</code>函数，代码如下：</p>

<pre><code>    if (sk_acceptq_is_full(sk))
        goto exit_overflow;
</code></pre>

<p>可以看到，这里会检查<code>accept</code>队列的长度。如果队列已满，跳到<code>exit_overflow</code>标签执行一些清理工作、更新<code>/proc/net/netstat</code>中的统计项<code>ListenOverflows</code>和<code>ListenDrops</code>，最后返回<code>NULL</code>。这会触发<code>tcp_check_req</code>函数跳到<code>listen_overflow</code>标签执行代码。</p>

<pre><code>listen_overflow:
    if (!sysctl_tcp_abort_on_overflow) {
        inet_rsk(req)-&gt;acked = 1;
        return NULL;
    }
</code></pre>

<p>很显然，除非<code>/proc/sys/net/ipv4/tcp_abort_on_overflow</code>被设置为<code>1</code>(这种情况下发送一个<code>RST</code>包)，实现什么都没做。</p>

<p>总结一下：<code>Linux</code>内核协议栈在收到3次握手最后一个<code>ACK</code>包，确认一个新连接已完成，而<code>accept</code>队列已满的情况下，会忽略这个包。一开始您可能会对此感到奇怪——别忘了<code>SYN RECEIVED</code>状态下有一个计时器实现：如果<code>ACK</code>包没有收到(或者是我们讨论的忽略)，协议栈会重发<code>SYN/ACK</code>包(重试次数由<code>/proc/sys/net/ipv4/tcp_synack_retries</code>决定)。</p>

<p>看以下抓包结果就非常明显——一个客户正尝试连接一个已经达到其最大<code>backlog</code>的<code>socket</code>：</p>

<pre><code>  0.000  127.0.0.1 -&gt; 127.0.0.1  TCP 74 53302 &gt; 9999 [SYN] Seq=0 Len=0
  0.000  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
  0.000  127.0.0.1 -&gt; 127.0.0.1  TCP 66 53302 &gt; 9999 [ACK] Seq=1 Ack=1 Len=0
  0.000  127.0.0.1 -&gt; 127.0.0.1  TCP 71 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  0.207  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  0.623  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  1.199  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
  1.199  127.0.0.1 -&gt; 127.0.0.1  TCP 66 [TCP Dup ACK 6#1] 53302 &gt; 9999 [ACK] Seq=6 Ack=1 Len=0
  1.455  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  3.123  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  3.399  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
  3.399  127.0.0.1 -&gt; 127.0.0.1  TCP 66 [TCP Dup ACK 10#1] 53302 &gt; 9999 [ACK] Seq=6 Ack=1 Len=0
  6.459  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
  7.599  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
  7.599  127.0.0.1 -&gt; 127.0.0.1  TCP 66 [TCP Dup ACK 13#1] 53302 &gt; 9999 [ACK] Seq=6 Ack=1 Len=0
 13.131  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
 15.599  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
 15.599  127.0.0.1 -&gt; 127.0.0.1  TCP 66 [TCP Dup ACK 16#1] 53302 &gt; 9999 [ACK] Seq=6 Ack=1 Len=0
 26.491  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
 31.599  127.0.0.1 -&gt; 127.0.0.1  TCP 74 9999 &gt; 53302 [SYN, ACK] Seq=0 Ack=1 Len=0
 31.599  127.0.0.1 -&gt; 127.0.0.1  TCP 66 [TCP Dup ACK 19#1] 53302 &gt; 9999 [ACK] Seq=6 Ack=1 Len=0
 53.179  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
106.491  127.0.0.1 -&gt; 127.0.0.1  TCP 71 [TCP Retransmission] 53302 &gt; 9999 [PSH, ACK] Seq=1 Ack=1 Len=5
106.491  127.0.0.1 -&gt; 127.0.0.1  TCP 54 9999 &gt; 53302 [RST] Seq=1 Len=0
</code></pre>

<p>由于客户端的<code>TCP</code>实现在收到多个<code>SYN/ACK</code>包时，认为<code>ACK</code>包已经丢失了并且重传它。如果在<code>SYN/ACK</code>重试次数达到限制前，服务端应用从<code>accept</code>队列接收连接，使得<code>backlog</code>减少，那么协议栈会处理这些重传的<code>ACK</code>包，将连接状态从<code>SYN RECEIVED</code>变更到<code>ESTABLISHED</code>并且将其加入<code>accept</code>队列。否则，正如以上包跟踪所示，客户读会收到一个<code>RST</code>包宣告连接失败。</p>

<p>在客户端看来，第一次收到<code>SYN/ACK</code>包之后，连接就会进入<code>ESTABLISHED</code>状态。如果这时客户端首先开始发送数据，那么数据也会被重传。好在<code>TCP</code>有慢启动机制，在服务端还没进入<code>ESTABLISHED</code>之前，客户端能发送的数据非常有限。</p>

<p>相反，如果客户端一开始就在等待服务端，而服务端<code>backlog</code>没能减少，那么最后的结果是连接在客户端看来是<code>ESTABLISHED</code>状态，但在服务端看来是<code>CLOSED</code>状态。这也就是所谓的半开连接。</p>

<p>有一点还没讨论的是：<code>man listen</code>中提到每次收到新<code>SYN</code>包，内核往<code>SYN</code>队列追加一个新连接(除非该队列已满)。事实并非如此，<code>net/ipv4/tcp_ipv4.c</code>中<code>tcp_v4_conn_request</code>函数负责处理<code>SYN</code>包，请看以下代码：</p>

<pre><code>    if (sk_acceptq_is_full(sk) &amp;&amp; inet_csk_reqsk_queue_young(sk) &gt; 1) {
        NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
        goto drop;
    }
</code></pre>

<p>可以看到，在<code>accept</code>队列已满的情况下，内核会强制限制<code>SYN</code>包的接收速率。如果有大量<code>SYN</code>包待处理，它们其中的一些会被丢弃。这样看来，就完全依靠客户端重传<code>SYN</code>包了，这种行为跟<code>BSD</code>实现一样。</p>

<p>下结论前，需要再研究以下<code>Linux</code>这种实现方式跟<code>BSD</code>相比有什么优势。<code>Stevens</code>是这样说的：</p>

<blockquote><p>在<code>accept</code>队列已满或者<code>SYN</code>队列已满的情况下，<code>backlog</code>会达到限制。第一种情况经常发生在服务器或者服务器进程非常繁忙的情况下，进程没法足够快地调用<code>accept</code>系统调用从中取出已完成连接。后者是<code>HTTP</code>服务器经常面临的问题，在服务端客户端往返时间非常长的时候(相对于连接到达速率)，因为新<code>SYN</code>包在往返时间内都会占据一个连接对象。</p>

<p>大多数情况下<code>accept</code>队列都是空的，因为一旦有一个新连接进入队列，阻塞等待的<code>accept</code>系统调用将返回，然后连接从队列中取出。</p></blockquote>

<p><code>Stevens</code>建议的解决方案是简单地调大<code>backlog</code>。但有个问题是，应用程序在调优<code>backlog</code>参数时，不仅需要考虑自身对新连接的处理逻辑，还需要考虑网络状况，包括往返时间等。Linux实现实际上分成两部分：应用程序只负责调解<code>backlog</code>参数，确保<code>accept</code>调用足够快以免<code>accept</code>队列被塞满；系统管理员则根据网络状况调节<code>/proc/sys/net/ipv4/tcp_max_syn_backlog</code>，各司其职。</p>

<p>本文译自：<a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">How TCP backlog works in Linux</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux文件描述符]]></title>
    <link href="http://blog.fasionchan.com/blog/2016/09/20/linux-wen-jian-miao-shu-fu/"/>
    <updated>2016-09-20T22:16:26+08:00</updated>
    <id>http://blog.fasionchan.com/blog/2016/09/20/linux-wen-jian-miao-shu-fu</id>
    <content type="html"><![CDATA[<p>在<a href="http://www.jianshu.com/p/5357d72ef17d">Linux通用I/O模型</a>中，<code>I/O</code>操作系列函数(系统调用)都是围绕一个叫做文件描述符的整数展开。这不禁让人产生疑问：这个整数代表什么？一个数值代表一个文件吗？随便传一个整数进去调用可以吗？</p>

<p>解答以上疑问，需要更深入学习——文件描述符(File Descriptor)。</p>

<!--more-->


<h1>图解</h1>

<p>理解具体情况，需要了解由内核维护的3个数据结构：</p>

<ul>
<li>进程级<strong>文件描述符表</strong>(file descriptor table)</li>
<li>系统级<strong>打开文件表</strong>(open file table)</li>
<li>文件系统<strong>i-node表</strong>(i-node table)</li>
</ul>


<p>这3个数据结构之间的关系如下图所示：</p>

<p><img src="/images/fd-inode-diagram.png"></p>

<h2>文件描述符表</h2>

<p>内核为每个进程维护一个<strong>文件描述符表</strong>，该表每一条目都记录了单个文件描述符的相关信息，包括：</p>

<ul>
<li><strong>控制标志</strong>(flags)，目前内核仅定义了一个，即<code>close-on-exec</code></li>
<li><strong>打开文件描述体指针</strong></li>
</ul>


<h2>打开文件表</h2>

<p>内核对所有打开的文件维护一个系统级别的<strong>打开文件描述表</strong>(open file description table)，简称<strong>打开文件表</strong>。表中条目称为<strong>打开文件描述体</strong>(open file description)，存储了与一个打开文件相关的全部信息，包括：</p>

<ul>
<li><strong>文件偏移量</strong>(file offset)，调用<code>read()</code>和<code>write()</code>更新，调用<code>lseek()</code>直接修改</li>
<li><strong>访问模式</strong>，由<code>open()</code>调用设置，例如：只读、只写或读写等</li>
<li><strong><code>i-node</code>对象指针</strong></li>
</ul>


<h2>i-node表</h2>

<p>每个文件系统会为存储于其上的所有文件(包括目录)维护一个<code>i-node</code>表，单个<code>i-node</code>包含以下信息：</p>

<ul>
<li><strong>文件类型</strong>(file type)，可以是常规文件、目录、套接字或<code>FIFO</code></li>
<li><strong>访问权限</strong></li>
<li><strong>文件锁列表</strong>(file locks)</li>
<li><strong>文件大小</strong></li>
<li>等等</li>
</ul>


<p><code>i-node</code>存储在磁盘设备上，内核在内存中维护了一个副本，这里的<strong><code>i-node</code>表</strong>为后者。副本除了原有信息，还包括：引用计数(从打开文件描述体)、所在设备号以及一些临时属性，例如文件锁。</p>

<h1>场景解析</h1>

<p>上图中，详细描述了两个进程诸多文件描述符，以及相互关系。</p>

<h2>文件描述符复制</h2>

<p>在进程<code>A</code>中，文件描述符1和文件描述符20都指向同一个打开文件描述体(标号23)。这很可能是通过调用<code>dup()</code>系列函数形成的。</p>

<p>文件描述符复制，在某些场景下非常有用，比如：标准输入/输出重定向。在<code>shell</code>下，完成这个操作非常简单，大部分人都会，但是极少人思考过背后的原理。</p>

<p>大概描述一下需要的几个步骤，以标准输出(文件描述符为1)重定向为例：</p>

<ol>
<li>打开目标文件，返回文件描述符n；</li>
<li>关闭文件描述符1；</li>
<li>调用<code>dup</code>将文件描述符n复制到1；</li>
<li>关闭文件描述符n；</li>
</ol>


<h2>子进程继承文件描述符</h2>

<p>进程<code>A</code>的文件描述符2和进程<code>B</code>的文件描述符2都指向同一个打开文件描述体(标号23)。这种情形很可能发生在调用<code>fork()</code>派生子进程之后，比如<code>A</code>调用<code>fork()</code>派生出<code>B</code>。这时，<code>B</code>作为子进程，从父进程<code>A</code>继承了文件描述符表，其中包括图中标明的文件描述符2。这就是<code>子进程继承父进程打开的文件</code>这句话的由来。</p>

<p>当然了，进程<code>A</code>通过<code>Unix</code>套接字将一个文件描述符传递给<code>B</code>也会出现类似的情形，但一般文件描述符数值是不一样的。同时为2要非常凑巧才发生。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux通用IO模型]]></title>
    <link href="http://blog.fasionchan.com/blog/2016/09/17/linux-tong-yong-io-mo-xing/"/>
    <updated>2016-09-17T21:54:29+08:00</updated>
    <id>http://blog.fasionchan.com/blog/2016/09/17/linux-tong-yong-io-mo-xing</id>
    <content type="html"><![CDATA[<p>学习<code>Linux</code>系统编程，文件I/O是一个不错的切入点。首先，日常操作中或多或少都使用过文件，有一定的概念；其次，文件I/O可以由几个最最基础的系统调用完成，降低入门理解难度。</p>

<h1>基础系统调用</h1>

<p><code>Linux</code>下<code>I/O</code>操作是通用化的，不仅仅可以用来操作文件输入输出，还可以用来操作管道、<code>FIFO</code>、<code>socket</code>、终端设备等。将设备抽象成一个文件，用<code>I/O</code>操作控制设备是类<code>Unix</code>系统一大特色。</p>

<!--more-->


<p>最最基础的<code>I/O</code>操作系统调用包括：</p>

<ul>
<li><strong>fd = open(pathname, flags, mode)</strong></li>
<li><strong>rlen = read(fd, buf, count)</strong></li>
<li><strong>wlen = write(fd, buf, count)</strong></li>
<li><strong>status = close(fd)</strong></li>
</ul>


<p>注意到，相关系统调用都围绕文件描述符<code>fd</code>展开。文件描述符在下节详细介绍。</p>

<p>另外，需要特别提示一下，系统调用函数接口（其实是库函数封装）可以通过<code>man</code>命令查看详细的参数、返回值及用法说明。比如，终端下运行<code>man read</code>，就可以看到<code>read</code>这个系统调用的相关文档说明：</p>

<p><img src="http://upload-images.jianshu.io/upload_images/2740477-bb2610e81244463b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="man open" /></p>

<h1>文件描述符</h1>

<p><code>I/O</code>操作系统调用都以文件描述符(一个非负整数)，指代打开的文件。每个进程都有一个打开文件表，可以理解成一个数组，文件描述符可以理解成数组的下标。相关<code>I/O</code>操作系统调用以文件描述符为参数，便可以通过数组访问定位到指定的文件对象，进而进行<code>I/O</code>操作。</p>

<p>一般情况下，进程的标准输入输出由3个特定的文件描述符指定，列举如下：</p>

<table>
<thead>
<tr>
<th style="text-align:left;">文件描述符</th>
<th style="text-align:left;">用途</th>
<th style="text-align:left;">POSIX名称</th>
<th style="text-align:left;">stdio流</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">0</td>
<td style="text-align:left;">标准输入</td>
<td style="text-align:left;">STDIN_FILENO</td>
<td style="text-align:left;">stdin</td>
</tr>
<tr>
<td style="text-align:left;">1</td>
<td style="text-align:left;">标准输出</td>
<td style="text-align:left;">STDOUT_FILENO</td>
<td style="text-align:left;">stdout</td>
</tr>
<tr>
<td style="text-align:left;">2</td>
<td style="text-align:left;">标准错误</td>
<td style="text-align:left;">STDERR_FILENO</td>
<td style="text-align:left;">stderr</td>
</tr>
</tbody>
</table>


<p>正常情况下，程序在开始运行之前，由<code>shell</code>准备好这3个文件描述符。更准确的说法是，程序继承了<code>shell</code>文件描述符的副本，一般是指向<code>shell</code>所在的终端。当然了，可以通过在<code>shell</code>中对输入/输出进行重定向或者在程序启动后关闭并重新打开文件描述符，修改文件描述符指向。</p>

<h1>实战案例</h1>

<h2>读文件</h2>

<p>首先，通过一个例子，探索一下如何通过<code>I/O</code>操作系统调用读取文件内容并输出：</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;fcntl.h&gt;

int
main(int argc, char *argv[])
{
    // 打开文件
    int fd = open("a.txt", O_RDONLY);
    if (-1 == fd)
    {
        perror("fail to open a.txt");
        return -1;
    }

    // 准备缓冲区并读文件
    char buf[1024];
    int rlen = read(fd, buf, sizeof(buf)-1);
    if (-1 == rlen)
    {
        perror("fail to read a.txt");
        return -2;
    }

    // 输出内容
    buf[rlen] = '\0';
    printf("read %d bytes, which is:\n", rlen);
    printf("%s\n", buf);

    // 关闭文件
    int status = close(fd);
    if (-1 == status)
    {
        perror("fail to close a.txt");
        return -3;
    }

    return 0;
}
</code></pre>

<h2>写文件</h2>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;fcntl.h&gt;

int
main(int argc, char *argv[])
{
    // 打开文件
    int fd = open("a.txt", O_WRONLY);
    if (-1 == fd)
    {
        perror("fail to open a.txt");
        return -1;
    }

    // 准备数据并写到文件
    char data[] = "hello, this is line written by write syscall\n";
    int wlen = write(fd, data, strlen(data));
    if (-1 == wlen)
    {
        perror("fail to read a.txt");
        return -2;
    }

    // 输出成功写入字节数
    printf("write %d bytes of %d total\n", wlen, strlen(data));

    // 关闭文件
    int status = close(fd);
    if (-1 == status)
    {
        perror("fail to close a.txt");
        return -3;
    }

    return 0;
}
</code></pre>
]]></content>
  </entry>
  
</feed>
